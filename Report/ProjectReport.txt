
Josh Keahey
Connor Blackstock
Analyzing Colleges
2nd May 2019
Introduction
In today’s day and age, higher education is a must for anyone looking to get a better paying job, or to be able to learn more about subjects they care about. Since this is generally agreed upon by most, many end up going to some kind of higher education institution, whether that’s a community college or a 4-year university. It is also well known that for the last 15 plus years, tuition has increased steadily like clockwork. Unfortunately, because of this change, debt for the average student has also increased. This has sadly become a common situation with students currently attending these institutions, or graduates of them leaving with thousands of dollars still owed. If you did not have any debts or outstanding loans because of higher education, chances are high that you at least know someone who has. It would be nice to have a good idea before signing up for four plus years at a specific university, if said university would be a good payoff for you. If you’re paying extra money for a more prestigious college, can you expect to get a career that pays well enough to support you - and perhaps a family - while still being able to pay off any loans accrued? This is what we set out to discover.
We tried to answer our question “Which college is the best bang for your buck?”, by using the College Scorecard [1] data set. This data set is federally created and maintained, and its purpose is to help prospecting students decide what college is the best choice for them. We found another smaller data set [2] (which we’ll call the majors income data set) as well, which contained 50 majors and their respective salaries. There have also been other interested researchers that have used the data set for determining insights into their own questions [3], [4].
This report will explain key attributes about our experience with the project, from early concepts and ideas, to coding, execution, and insights. First, we addressed the problem, which was already described above as getting the most for your dollar in higher education. Maybe you spend more than usual like going to CU Boulder, but will you get a better paying job to help with the cost of going in the first place? What if you’re coming from across the country and are paying out-of-state tuition? What if you’re an independent student, not relying from mom and dad pitching in to help with costs? There were a few different ways we tried to tackle these questions, and plenty of road bumps along the way. We explain how we think we answered these questions (and got over the speed bumps) later on, in how we approached the problem. Once we had a good idea of how we could use logic and an algorithm of our own, we could then look at answers we got and see if it made sense. Our solution isn’t a hard figured, black and white, wrong or right answer, so it was tough to figure out how we did, but at the end of it all, we were pretty confident in what we made.
With all this in mind, let’s now get into the project itself.
Problem Characterization
Finding the right college for every person can be tough because there are so many factors to consider. Some of the most important factors to consider are amount of debt, and how much money will be made annually after college. To find out this information there are too many factors that can contribute to this. However, the College Scorecard data set and income data set can quantify some of these factors like average income for majors, and cost of college annually for several different financial cases. The problem with these data sets, is that they cannot measure or compare the strength of the education provided by an institution. This makes predicting how much money graduates will make after college quite tough; due to not being able to measure ability which has an effect on income. Therefore, another way to measure potential success has to be found, in order to provide the most accurate prediction. Finding the colleges that provide the most “bang for your buck” relies on quantifying factors that are qualitative.
Can we find an answer to the question “Which College is the best bang for your buck?”. As undergraduates know all too well, getting through College without debts or loans is no easy feat [5]; wouldn’t it be nice to have a good idea that the money you put into school has a great return in the future? Comparing different potential choices wouldn’t hurt either. Generally speaking, paying more to an institution might mean it’s more difficult to get into or more prestigious. The question then becomes, will the job you receive upon completing your time there pay you significantly more than if you went to a cheaper school for the same major? For some, money isn’t an issue, and this ‘problem’ doesn’t mean much to them; but for the vast majority, it does. As mentioned above, there are a plethora of dynamic circumstances that could change in trying to obtain this answer. A problem with the College Scorecard data set in particular is that it has the same issue as many other data sets; not being very clean. Even though it contained possibly informative columns for student data, such as median debt per college, average household income, and admissions rates, all of them contained the string ‘NULL’, rendering them useless. This makes determining an algorithm to the problem more challenging, even after cleaning it up.
There is also the issue of asking a question in which there is no ‘right’ answer. We can’t find the root mean squared error or take the derivative of something to form an answer saying, ‘Go to this school!’. This also means there isn’t a ‘wrong’ answer as well, but it should be easier to tell when any answers are off by using common sense. If you’re an independent student from Colorado, and want to major in Music, then you would expect MIT, Harvard and the University of Maine to not be on any list for you. Knowing these few problems beforehand should help us decide the best way to conquer them, and obtain an answer we’re confident in.
Approaches to the Problem
Assumptions have to be made about the individuals that make up each institution’s percentages and findings. First is that college graduates will attempt to pay a percentage of their earnings when they have enough money to do so. Second is that college graduates will pay about the same percentage of their annual earnings towards their student loans. An example of this is, there are two graduates, one makes 100k a year and one makes 90k a year. We assume that student one will pay 5k while the other will pay 4.5k, so that a graduate that makes more is paying more than the other. By making this assumption, repayment rates can be used to estimate the odds that a graduate is making enough money to pay off their loans. The assumption is required because if a graduate is only making 30k a year, it might be hard to make payments on their student loans.
The algorithm attempts to take into account a schools strong suits by using major percentages. The College Scorecard data set contains information about the percent of students that graduate from each major. The reason this may be a good indicator is that some schools only offer a select few majors or are well known for a certain major. For example an Art school like Julliard, it is expected that the majority, if not all, majors that graduate are of the same degree type. It will also filter out colleges that don’t offer that don’t offer degrees of that type. 
A few command line arguments are needed to hopefully estimate debt and potential earnings. They are the student’s state, whether they are dependent or independent, and the major they would like to study. This information provides accurate tuition costs per year, which can be adjusted whether they are dependent or independent. The major provides yearly income during the middle of the graduates career, which will be averaged because the data set has general categories for majors. For example chemical engineering would be engineering which is averaged with mechanical and civil engineering. The algorithm is simple, (debt/income)*(1 - repayment rate)*major percentage. The result is a score and the lower the score is, the better the college ranks.
Our Methodology 
The College Scorecard, which interestingly enough was redesigned in 2015 by the Obama administration in September 2015 [6]. The Scorecard had been around since the mid 90’s, and was not exactly maintained very well, as we found out during the cleaning phase. The makeover from the set was meant to be the most reliable, comprehensive, and nationally comparable data ever made on higher education institutions. The data set is quite large, even though it is a little over one gigabyte, it contains over 1900 columns and spans over a 21 year period with over 7000 institutions. With that being said, getting rid of unimportant information and unusable data is important, especially when speed is important. Therefore, before the analysis program is run, a preprocessing job has to be run. The preprocessing job eliminates all but 21 columns. This makes the analysis program run much faster than having to load in over 299 million data fields, most of which will not be used.
The majors income data set was hand compiled and given a type based on the given major categories given in the College Scorecard data set. 
The analysis program takes the three arguments referred to in the approach section, other than the arguments to point to the data sets. The majors data set is loaded in and using Apache Spark SQL, fetches the income data for the specific major provided. The major type may not be unique and may fetch multiple records, like the engineering example. An average income will be taken to account for these variations. Next, the newly filtered College Scorecard data set is loaded in a converted to a pair RDD, with the college id as the key and the other columns as the value. The RDD is then run through a filter, to remove all values (College for a specific year)  with null or privacy suppressed values. Removing these values ensures that the results will not be skewed by these values, since the average score for each college will be taken at the end of the analysis job. The analysis then begins by mapping this RDD to a score for each year per college, this score is generated using the algorithm listed above. Since this is over 21 years, each colleges score needs to be averaged using the aggregateByKey( ) function. At this point, the RDD contains a single score for each college. As pointed out earlier, lower scores equate to a higher ranking. A treemap is used to rank these colleges, then at the end, the top 20 are selected.
Experimental Benchmarks
As we stated before, it was difficult to determine the accuracy of our answers in the top 20 schools, as it was quite subjective. We could however, perform other methods of attempting to verify accuracy. Using the command line for one, and double checking the data for the colleges themselves once we had the final list for another. By giving different states, dependent or independent values, and different majors as arguments, dynamic and unique tests could be done to check validity. In doing this, we could act as if we were students from all over the country, and see if the colleges output made sense. For some of the cases, we would select the top 3 and actually go into the data set, look at the numbers in each field, and try to see why it was placed so high. Using this helped us decide if what we were getting was any good. 
Also, just being able to see the list of top 20 institutions itself was a help. For the most part, if you were a dependent student, the list would primarily be made up of colleges in the same state, since we took in-state and out-of-state tuition into account. There would be schools from other states in the mix as well though, which also makes some sense. After going through some of the csv files from the data set, sometimes a university’s out-of-state tuition wouldn’t be nearly as high as others, or could even be the same price as its in-state tuition. This was particularly interesting, because it happened more often than we thought it would. Overall, the accuracy seemed adequate given the data set and arguments a prospective student would give the program.
As far as turnaround times and throughputs go, there was never a problem with either. The College Scorecard was just over 1GB, so Spark had no problem going through the initial data and picking out the columns needed for our second Spark job. Even though there ended up being thousands of colleges after filtering out any that had bad or empty data fields, the second job flew by, and within 45 - 60 seconds of starting our first job, we would have results from the second. If the size of the data set was much larger, or if the entirety of this data set was used for the project, different approaches might need to be taken to keep the turnaround times and throughputs low. The reason is because we used the aforementioned Spark function aggregateByKey( ), which is a wide transformation. These wide transformations are well known to potentially slow down Spark processes by causing a shuffling of the data in the RDD. If the amount of data being utilized was 10 fold in size, we could see a slow down in our program execution. Knowing this, we would still use the same code we are using now, but depending on wait times, that could be changed in the future if needed. 
Insights Gleaned
In terms of output from the program, it is very dependent on the arguments. For example, a person from Colorado who is dependent and wants to major in engineering would be recommended the University of Colorado - Boulder. In testing, usually the in-state colleges dominate the output, but there are schools from other states that make the top 20 every now and then.
As far as what can be learned from writing this program, Apache Spark makes creating iterative computation very easy. The computation and loading of data is around 50 lines of code. Another takeaway from this experience, is that Apache Spark SQL is very brittle. This is in the sense that everything has to be perfect with the data and the query has to be in the way it wants. For example, initially the College Scorecard data set was not preprocessed and the program attempted to query the data set to retrieve the columns. Apache Spark SQL does not like full SQL queries in the form of a string that attempts to use filter out rows. It throws parse errors until the query is in the form of a set of columns with filters attached to them. After that, the schema that it thinks the data set - in this case the csv - is in, is not what it should be. The query was returning all booleans evaluating to true, which is nothing like the contents of the file. Hence, making debugging a nightmare. When loading a csv, there are several options to create a schema for the data set. None of them worked, even when explicitly providing a schema. Quite a bit of time was spent trying to figure out how data could go from an obvious string in the College Scorecard data set, (such as “Colorado State University”) to the boolean value ‘true’ in our RDD. This lead to the end result of having a seperate preprocessing job that does not incorporate SQL to collect only the pertinent columns. Long story short, when in doubt filter using RDD functions instead of SQL. Thankfully, it did not have any issues with the secondary majors income data set.
The last humbling experience was the fact that the College Scorecard data set, even though overall had some good information and was created by the United States government, had plenty of useless data fields. Whether these fields contained a Privacy Suppressed string explaining that they can’t display or report that information, to the NULL’s scattered about, cleaning was a very real issue. Where before, data sets had been used that were either very well put together or much smaller, it was a new experience to need to make sure good, useable data was given to our second Spark job. Learning to deal with that issue will be helpful in the future.
Transformation of the Problem Space in the Future
The problem space will most likely not change too much in the future. However, there may be more colleges and will obviously have more usable information, especially when the world is becoming more data driven. The early years in the College Scorecard data set have an excessive amount of null values. This is probably because the data set starts in the school year from 1996 to 1997, when the acquisition of data from colleges - especially nation wide - wasn’t very common in the budding new internet. Luckily, the later years have more data that can be analyzed. Hopefully there will also be new columns added which allow for more accurate results. Obviously, less null  and privacy suppressed fields wouldn’t be amiss. Currently, the data set contains mean and median income from each college. However, this is not accurate when considering majors. This is due to the fact that some majors make more than others. If a school only offers art or business and is compared to a school that offers only engineering, the engineering school would always report higher incomes. Therefore, mean and median incomes per major would improve this analysis in the future.
Hopefully more and more schools report their numbers on columns present in the data set already. As mentioned earlier, many potential very interesting columns such as the median debt of students with family income between $30,001 - $75,000. Unfortunately, after the data was read in, virtually all colleges had a null value in its place. This happened with a few different ideas we had earlier in the project. With most of these fields filled in in the future, who knows all the kinds of cool and compelling data that could be discerned from this data set. Even with what’s just there now, we found a couple other instances of curious data programmers take it and come up with some pretty cool assertions (See [3] and [4]). Even though college enrollment had a slight peak in 2010 [7] and then dropped off a little, it is projected to rise in the next five to six years. With this in mind, more and more students will be entering the college experience, and the way things have been going for some time now when it comes to tuition, it will be rising as well. Because of this direct correlation, more and more students (and parents) would presumably want to know if the school they pick is the best for the student. With additional data in the College Scorecard, complete data with further research can be done to help aid them in this important life decision.
Conclusions

Bibliography
[1] Fu, Brian. “College Scorecard” 09/29/2017                                         https://catalog.data.gov/dataset/college-scorecard
[2] Desjardins, Jeff. Which College Degrees Get the Highest Salaries?” 07/25/2018 https://www.visualcapitalist.com/visualizing-salaries-college-degrees/ 
[3] Brainerd, Andrew. “Examining Higher Education in the United States with the College Scorecard Dataset” 10/15/2017	https://nycdatascience.com/blog/student-works/examining-higher-education-united-states-college-scorecard-dataset/
[4] Dean, Jason. “​College Scorecard Data Analysis and GBM Model of Predictive Earnings” 03/14/2017 http://jasontdean.com/R/collegeScoreCard.html 
[5] Hess, Abigail.  “Here’s how much the average student loan borrower owes when they graduate” 02/15/2018 https://www.cnbc.com/2018/02/15/heres-how-much-the-average-student-loan-borrower-owes-when-they-graduate.html
[6] No author. “FACT SHEET: Obama Administration Announces Release of New Scorecard Data” 09/14/2016 https://www.ed.gov/news/press-releases/fact-sheet-obama-administration-announces-release-new-scorecard-data
[7] No author. National Center for Education Statistics. 03/2018         https://nces.ed.gov/programs/coe/indicator_cha.asp
[8] WOO HOO! ONLY ONE MORE NEEDED
